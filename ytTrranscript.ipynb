{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf537265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, langchain, pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "from uuid import uuid4\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd\n",
    "from langchain.chains import RetrievalQA\n",
    "from pytube import YouTube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import tiktoken\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import Tool\n",
    "from langchain import OpenAI, SQLDatabase\n",
    "import googleapiclient.discovery\n",
    "import re\n",
    "from langchain.chains import SQLDatabaseSequentialChain\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "import random\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e6f3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_API_KEY = \"\" \n",
    "YOUR_ENV= \"us-west1-gcp-free\"\n",
    "\n",
    "index_name = 'chatfast'\n",
    "\n",
    "pinecone.init(\n",
    "                api_key=YOUR_API_KEY,\n",
    "                environment=YOUR_ENV\n",
    ")\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "                # we create a new index\n",
    "    pinecone.create_index(\n",
    "                    name=index_name,\n",
    "                    metric='dotproduct',\n",
    "                    dimension=1536  # 1536 dim of text-embedding-ada-002\n",
    "                )\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30ecdb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com/watch?v=fuhE6PYnRMc&ab_channel=MrBeast\n"
     ]
    }
   ],
   "source": [
    "     ##we need to define a url var\n",
    "url = \"https://www.youtube.com/watch?v=fuhE6PYnRMc&ab_channel=MrBeast\"\n",
    "print(url)\n",
    "match = re.search(r\"watch\\?v=(.{11})\", url)\n",
    "result_id = match.group(1)\n",
    "            ### This will be the start of if logic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636cb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(text,source_title):     \n",
    "    text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_text(text)\n",
    "    messages=limit_check(texts)\n",
    "    print(len(messages))\n",
    "    api_key = \"OpenAI API KEY HERE\"\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "    metadata = [{\"source_title\": source_title }] * len(messages)\n",
    "    Pinecone.from_texts([t for t in messages],embeddings,index_name=\"chatfast\",metadatas=metadata, namespace='')\n",
    "\n",
    "def create_chunks(text):\n",
    "    char_text_splitter = RecursiveCharacterTextSplitter(chunk_size=20, chunk_overlap=0)\n",
    "    texts = char_text_splitter.split_text(text)\n",
    "    return texts\n",
    "\n",
    "def limit_check(text):\n",
    "    messages=[]\n",
    "    for item in text: \n",
    "        messages.append(item)  \n",
    "        token_count = get_token_count(messages)\n",
    "        if token_count >= 5800:\n",
    "            messages.pop()\n",
    "            break\n",
    "        # print(token_count)\n",
    "        # print(len(messages))\n",
    "    return messages\n",
    "\n",
    "def get_token_count(messages):\n",
    "    tokens = num_tokens_from_messages(messages)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model == \"gpt-3.5-turbo\":  # note: future models may deviate from this\n",
    "        num_tokens = 0\n",
    "        for value in messages:\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "        return num_tokens\n",
    "        \n",
    "    else:\n",
    "        raise NotImplementedError(f\"\"\"num_tokens_from_messages() is not presently implemented for model {model}\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5ef43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "index = pinecone.Index('chatfast')\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=YOUR_API_KEY,\n",
    "    environment=YOUR_ENV\n",
    "        )\n",
    "index_name = 'chatfast'\n",
    "transcript = YouTubeTranscriptApi.get_transcript(result_id)\n",
    "response = [d['text'] for d in transcript if 'text' in d]\n",
    "text=\"\".join(response)\n",
    "source_title=result_id\n",
    "texts=load_file(text,source_title)               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eccfa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OPENAI_API_KEY=\"OpenAI API Key Here\"\n",
    "            # chat completion llm\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "doc_search = Pinecone.from_existing_index(index_name=\"chatfast\", embedding=embeddings)\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name='gpt-4',\n",
    "    temperature=0.0\n",
    "            )\n",
    "            # conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    "            )\n",
    "            # retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=doc_search.as_retriever(),\n",
    "    verbose=True\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "532cebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, someone won money. They won $95,000.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(\"Did anyone win money and how much?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbce7a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46bc9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62afc35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
